{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Example: Build Decision Tree Models to Identify Key Risk Indicators "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define functions to calculate Weight of Evidence (WOE) and Information Value (IV) - for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import pandas from pd\n",
    "import numpy as np\n",
    "\n",
    "# Read data\n",
    "data = pd.read_csv('~/raw_data.csv', sep = ',', na_values = ['.']).drop(['unused_feature1'], axis = 1)\n",
    "\n",
    "# Define function to calculate WOE and IV\n",
    "def calc_woe_iv(data, target, grp_nbr = 10, print_iv = False):\n",
    "    \n",
    "    # Create two empty dataframes for final output\n",
    "    all_woe, all_iv = pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    # Get column names from raw data\n",
    "    cols = data.columns\n",
    "    \n",
    "    # Calculate WOE and IV for all independent variables\n",
    "    for feature in cols[~cols.isin([target])]:\n",
    "        if (len(np.unique(data[feature])) > 10):\n",
    "            x_grp = pd.qcut(data[feature], grp_nbr, duplicates = 'drop')\n",
    "            data_grp = pd.DataFrame({'x': x_grp, 'y': data[target]})\n",
    "        else:\n",
    "            data_grp = pd.DataFrame({'x': data[feature], 'y': data[target]})\n",
    "            \n",
    "        data_woe = data_grp.groupby('x', ax_index = False).agg({'y': ['count', 'sum']})\n",
    "        data_woe.columns = ['group', 'tot_cnt', 'bad_cnt']\n",
    "        \n",
    "        # Adjusted WOE is used to avoid zero bad or zero good\n",
    "        data_woe['bad_percent'] = np.maximum(data_woe['bad_cnt'], 0.5) / data_woe['bad_cnt'].sum()\n",
    "        data_woe['good_cnt'] = data_woe['tot_cnt'] - data_woe['bad_cnt']\n",
    "        data_woe['good_percent'] = np.maximum(data_woe['good_cnt'], 0.5) / data_woe['good_cnt'].sum()\n",
    "        data_woe['woe'] = np.log(data_woe['good_percent'] / data_woe['bad_percent']) \n",
    "        data_woe['iv'] = (data_woe['good_percent'] - data_woe['bad_percent']) * data_woe['woe']\n",
    "        \n",
    "        # Generate list for WOE and IV\n",
    "        data_woe.insert(loc = 0, collumn = 'feature', value = feature)\n",
    "        data_iv = pd.DataFrame({'feature': [feature], 'iv': [data_woe['iv'].sum()]})\n",
    "        all_woe = pd.concat([all_woe, data_woe], axis = 0)\n",
    "        all_iv = pd.concat([all_iv, data_iv], axis = 0)\n",
    "        \n",
    "        # Show WOE and IV tables\n",
    "        if print_iv == True:\n",
    "            print(all_woe)\n",
    "            print(all_iv)\n",
    "    return all_woe, all_iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Conduct feature selection based on Information Value - using 0.1 as threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function to get WOE and IV for all independent variables\n",
    "info_value, weight_of_evi = calc_woe_iv(data = data, target = 'target', grp_nbr = 10, print_iv = False)\n",
    "\n",
    "# Remove features with IV < 0.1\n",
    "feature_drop = info_value[info_value.iv < 0.1]\n",
    "feature_drop = feature_drop.feature.to_list()\n",
    "\n",
    "selected_data = data.loc[:, ~data.columns.isin(feature_drop)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset\n",
    "X = selected_data.drop(['target'], axis = 1)\n",
    "Y = selected_data['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate model performance and visualize trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "# Calculate and print confusion matrix, classification report and accuracy\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Classification report includes precision, recall, f1-score, and support\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(\"accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Calculate and visualize ROC curve\n",
    "roc_auc = metrics.roc_auc_score(y_test, clf.predict(X_test))\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, clf.predict_prob(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.show()\n",
    "\n",
    "# Plot trees\n",
    "plt_tree = tree.plot_tree(decision_tree = clf, feature_names = X.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
